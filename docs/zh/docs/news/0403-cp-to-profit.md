# “AI 流程编排”化算力为“算利”

> 国家级专精特新“小巨人”企业发布算力生态平台
>
> 来源：[解放日报](https://www.shobserver.com/staticsg/res/html/journal/detail.html?date=2024-04-02&id=370048&page=07)；记者：俞陶然

人工智能大模型的兴起，让 GPU（图形处理器）算力成为极其重要的资源。在这个领域，GPU 算力云服务扮演着重要角色，可以实现算力资源跨地区、跨行业的自由流动。
最近，国家级专精特新“小巨人”企业——上海道客，联合行业伙伴发布了“d.run 算力一体化方案”。这个方案包括上海、合肥等地的算力中心服务，
算法开发、模型微调等模型开发工具以及智能应用、流程编排等应用开发工具，为用户提供一个 AI 算力生态平台。

## AI 基础设施

近 5 年来，我国算力产业规模快速增长，年均增速超过 30%，但还存在核心芯片和国产基础软件生态不强、传输能力不足、无效算力增多等挑战。
上海道客创始人、首席执行官陈齐彦认为，大模型兴起后，除了 GPU 芯片供给不足，我国人工智能产业还面临协同服务、落地应用等方面的问题。
如何提高国内已有算力的使用效率？这需要包括云服务供应商在内的算力产业链上所有企业的共同努力，打造出全方位的算力一体化解决方案。

2014 年，来自易安信 EMC 中国研究院的陈齐彦团队走上创业道路，他们专注于云原生领域，使上海道客逐渐成长为这一领域的头部企业。
所谓云原生，是一系列云技术和开发管理方法的集合，它们试图在动态环境中寻找最优解，可通过调度发挥算力的最大效能，实现算力资源的灵活按需分配。
在云原生开源社区，道客对核心开源项目 Kubernetes 的贡献度排名全球第三，仅次于谷歌和红帽公司。

如今，这家上海企业基于云原生技术，与猴子无限等企业联手开发了旨在让算力更自由的“d.run 算力一体化方案”。
访问 d.run，记者看到 4 个板块：算力集群、模型应用、模型工具和管理。在算力集群板块，用户可购买上海、合肥等地的 GPU 算力；
在模型应用板块，可使用语料库、各种插件和数据分析工具，对垂直类模型应用进行训练和评测；在模型工具板块，多种算法开发、模型微调类工具供用户选择，包括训练大模型所必需的数据集。

“我们希望借助这个平台打通从 GPU 供应到协同服务，再到落地应用的产业链，让 AI 基础设施像水和电一样流向客户，
助力提升我国人工智能产业的有效算力，化算力为‘算利’。”陈齐彦在发布会上说。

## 智能体工作流

作为上海道客的合作伙伴，北京猴子无限公司为 d.run 开发了流程编排模块。这家企业获得了奇绩创坛创始人、百度原总裁陆奇的投资，专注于模型调优。
公司创始人、首席执行官尹伯昊介绍，斯坦福大学教授、著名人工智能专家吴恩达最近在社交平台 X 上表示：“智能体工作流”今年将推动人工智能快速发展，其智能水平可能超过下一代基础大模型。

什么是“智能体工作流”？目前，大语言模型根据提示词输出一篇文章，是直接生成的，这相当于人类写文章时不做任何修改，所以文章质量往往并不是很高。
“智能体工作流”则与人类写文章的过程很接近，将工作流程分为写提纲、收集信息、写初稿、修改初稿等若干步骤。
在执行每个步骤时，用户都可以介入，让“智能体工作流”生成的内容更符合自己的要求。

对于吴恩达的观点，尹伯昊十分认同：“流程数据是通向智能体的钥匙，流程驱动可以让大模型更优、更快地落地。”
为此，他带领团队正在构建以流程为中心的大模型落地平台，并与上海道客合作，将“流程编排”模块嵌入 d.run 平台。
在云原生的高可用环境中，很多企业可以为 AI 开放生态平台赋能，构建一套体系化流程，助力用户更快地开发出高质量的 AI 大模型应用。

吴恩达团队的实验研究发现：在零样本条件下，GPT-3.5 生成内容的正确率为 48.1%，GPT-4 的正确率达到 67.0%；
如果采用“智能体工作流”模式，GPT-3.5 的正确率高达 95.1%，远超 GPT-4。这个对比实验给尹伯昊团队带来了很大信心，
而在“实战”环境中，以流程为中心的大模型落地平台能否催生高质量的 AI 大模型应用？还有待用户检验。

[注册并体验 d.run](https://console.d.run/){ .md-button .md-button--primary }
