---
hide:
  - toc
---

# AI Industry News

This channel will closely follow technology trends and collect news from the AI industry.

* [Inside vLLM: Anatomy of a High-Throughput LLM Inference System](./2025/inside-vllm.md)

    From paged attention, continuous batching, prefix caching, specdec, etc. to multi-GPU, multi-node dynamic serving at scale

* [KV-Cache Wins You Can See: From Prefix Caching in vLLM to Distributed Scheduling with llm-d](./2025/kvcache-wins-you-can-see.md)

    How does llm-d enable smarter, prefix-aware, load- and SLO-aware routing for better latency and throughput?

* [CUDA Core Dump: An Effective Tool to Debug Memory Access Issues and Beyond](./2025/cuda.md)

    Uncover some of advanced debugging techniques we use that can help users debug complicated issues in vLLM, such as IMA.

- [LMCache supports gpt-oss (20B/120B) on Day 1](./2025/lmcache.md)

    LMCache now supports OpenAI’s newly released GPT-OSS models (20B and 120B parameters)
    from day one! This post provides a complete guide to setting up vLLM with LMCache for
    GPT-OSS models and demonstrates significant performance improvements through our CPU
    offloading capabilities.

- [FlowSpeech: The World’s First TTS Converting Written Language into Spoken Language](./2025/flowspeech.md)

    Artificial intelligence voice synthesis technology has reached a new breakthrough. An AI text-to-speech tool named FlowSpeech has been officially released, distinguished by its ability to convert written text into natural, fluent spoken language, providing users with a voice synthesis experience closer to real conversation.

- [GPT-5 Official Release: The Largest Product Upgrade in OpenAI’s History — Full Analysis of All Four Versions](./2025/gpt5.md)

    On August 7, 2025, OpenAI officially released the GPT-5 series models, marking the most significant product upgrade in the company’s history. The release includes GPT-5, GPT-5Mini, GPT-5Nano, and GPT-5Pro, each deeply optimized for different application scenarios. This milestone signifies a new era of AI development.

- [Announcing the llm-d community!](./2025/llmd.md)

    llm-d is a Kubernetes-native high-performance distributed LLM inference framework,
    a well-lit path for anyone to serve at scale, with the fastest time-to-value and competitive performance per dollar for most models across most hardware accelerators.

- [Deploy, Invoke, and Try DeepSeek on d.run](./2025/0210-deep-drun.md)

    This is a quick start guide that teaches you how to deploy DeepSeek models in d.run and use the DeepSeek model service within d.run or any third-party application.


- [AI Trends for 2025](./2025/0102-ai-trend.md)

    As technology races forward, artificial intelligence (AI) is becoming an essential part of our everyday lives.
    From smart assistants to automated processes, AI's applications touch nearly every aspect of society.
    Looking ahead to 2025, several key trends in AI development are poised to shape the future of this
    technology in profound ways.

- [Why K8s and Generative AI Are a Perfect Match](2024/0702-k8s-for-genai.md)

    Kubernetes (K8s) is no longer just a tool for running workloads (like web applications and microservices);
    for large artificial intelligence (AI) and large machine learning (ML) workloads such as large language models (LLM), K8s is the ideal platform for end-to-end lifecycle management.

- [OpenAI GPT-4o Now Completely Free](2024/0514-gpt4o.md)

    OpenAI is revolutionizing the world: GPT-4o is now completely free, with real-time voice and video interaction stunning everyone, directly entering the sci-fi era!

- [OpenAI Large Language Model Specifications](2024/0509-model-spec.md)

    This is the latest model specification released by OpenAI, which is a document specifying the expected behavior of models in the OpenAI API and ChatGPT,
    including a set of core objectives and guidance on how to handle conflicting objectives or instructions.

- [2024 Large-Scale AI Infrastructure Survey](2024/0429-ai-survey.md)

    ClearML has released the results of a global AI survey conducted with FuriosaAI and the Artificial Intelligence Infrastructure Alliance (AIIA).

- [Cloud-Native Artificial Intelligence White Paper](2024/0410-cnai-wp.md)

    This cloud-native artificial intelligence white paper first outlines the current state of AI/ML technology development, then introduces the support provided by cloud-native technologies, analyzes the challenges and shortcomings currently faced, and explores the continuously evolving solutions.

- [After Kimi's Success, Other Major Models in China Feel the Pressure](2024/0408-after-kimi.md)

    Influenced by Kimi, Baidu's Wenxin Yiyan and Alibaba's Tongyi Qianwen,
    have seen a significant drop in user access, with declines of 33.42% and 45.05% respectively.

- [Introducing DBRX: A New, Powerful Open Source LLM Model](2024/0407-dbrx.md)

    Introducing DBRX, an open general LLM created by Databricks.
    In a series of standard benchmark tests, DBRX has set new technical standards among established open LLMs.

- [“AI workflow orchestration” Turns computing resource into “Profit”](2024/0403-cp-to-profit.md)

    The national-level specialized and innovative "little giant" enterprise DaoCloud has launched the computing resource ecosystem platform d.run.

- [Who Will Replace the Transformer?](2024/0327-transformer.md)

    The Transformer started with Google's 2017 paper "Attention Is All You Need,"
    but why has it been popularized by OpenAI and dominated the field?
    What common challenges do non-Transformer models face?

- [The Financial Industry Enters the Era of LLMs, Computing Infrastructure Becomes the Key to Victory](2024/0326-compute-power.md)

    DaoCloud is leading a seminar on computing resource and LLM industries organized by the local financial industry in Shanghai.

[Register and Try d.run](https://console.d.run/){ .md-button .md-button--primary }
